{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "Este código implementa uma versão simples do algoritmo de classificação KNN. Por \"simples\" quero dizer que há implementações mais eficientes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vote_histogram: esta função faz a contagem das classes dos k vizinhos mais próximos.\n",
    "#Já recebe o vetor com os k mais próximos.\n",
    "def class_histogram(kn_neighbors, n_classes):\n",
    "    #Cria um vetor c zerado com n_classes posições\n",
    "    c = [0] * n_classes\n",
    "    #Para cada vizinho entre os k mais próximos\n",
    "    for i in kn_neighbors:\n",
    "        #incrementar contagem\n",
    "        c[i]+=1\n",
    "    #retornar contagem das classes dos k vizinhos mais próximos\n",
    "    return c\n",
    "\n",
    "#Faz a classificação do exemplo x baseado nos k mais próximos em X_train.\n",
    "def knn(X_train, Y_train, x, k):\n",
    "    #Calcula o vetor de distâncias entre x e todos os pontos em X_train\n",
    "    d = euclidean_distances(x.reshape(1,-1), X_train).reshape(-1)\n",
    "    #Ordena o vetor d e retorna os índices da ordenação em relação ao vetor d original. Não mexe no vetor d.\n",
    "    #Isto ajuda pq é necessário indexar Y_train das posições correspondentes depois da ordenação!\n",
    "    idx = np.argsort(d)\n",
    "    #Calcula a contagem das classes dos k vizinhos mais próximos:\n",
    "    #    Y_train[idx][:k] <-- pega os rótulos dos k vizinhos mais próximos!\n",
    "    hist = class_histogram(Y_train[idx][:k], len(set(Y_train)))\n",
    "    #hist apenas é um vetor [c0, c1, c2, ..., c_nclasses] de forma que c0 é a quantidade de vizinhos mais próximos\n",
    "    #que são da classe 0, c1 é a quantidade de vizinhos mais proximos que são da classe 1, e assim por diante.\n",
    "    \n",
    "    #Conforme vimos, o knn classifica x como sendo da classe com a maior quantidade de vizinhos mais próximos.\n",
    "    #assim, basta retornar a posição da classe que tem a maior quantidade de vizinhos mais próximos!\n",
    "    #    ex: se np.argmax(hist) == 0, a classe 0 tem a maioria dos vizinhos mais próximos de x.\n",
    "    return np.argmax(hist)\n",
    "\n",
    "def knn_2():\n",
    "    #Uma das formas de acelerar é passar o X_test todo. Acredito que a implementação do euclidean_distances\n",
    "    #é eficiente para computar tudo de uma vez (com implementação vetorial)\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.99\n"
     ]
    }
   ],
   "source": [
    "#Carrega o toy dataset ``digits'' do sklearn. Esse dataset é composto de 1797 imagens de dígitos manuscritos 8x8 em \n",
    "#16 tons de cinza. Há 64 características por imagem, uma para o valor de cada pixel.\n",
    "X, Y = load_digits(return_X_y=True)\n",
    "\n",
    "#Vamos dividir o dataset com 80% no treino e 20% no teste.\n",
    "#X_train é o conjunto de treino com os exemplos e Y_train são os gabaritos de cada exemplo de X_train.\n",
    "#X_test é o conjunto de treino com os exemplos e Y_test são os gabaritos de cada exemplo de X_test\n",
    "#se shuffle=True, \"embaralha\" o dataset antes de fazer a separação.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
    "\n",
    "misses = 0\n",
    "hits = 0\n",
    "k = 3\n",
    "\n",
    "#Para cada exemplo no conjunto de teste\n",
    "for i, x in enumerate(X_test):\n",
    "    #Classificar o exemplo. Se o exemplo estiver correto (for igual do gabarito)\n",
    "    if knn(X_train, Y_train, x, k) == Y_test[i]:\n",
    "        #incrementar os acertos\n",
    "        hits+=1\n",
    "    else:\n",
    "        #Senão, incrementar os erros\n",
    "        misses+=1\n",
    "\n",
    "#A acurácia é dada por acertos / (acertos + erros).\n",
    "print (\"acurácia: %.02f\" % (hits / float(hits + misses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação cruzada para otimização do hiperparâmetro $k$\n",
    "\n",
    "Note que $k$ é um parâmetro do classificador KNN, ou seja, $k$ é um valor que deve ser escolhido para que o KNN funcione. Entretanto, este parâmetro tem impacto direto no resultado da classificação.\n",
    "\n",
    "Como escolher $k$ para que o sistema obtenha o melhor resultado possível?\n",
    "\n",
    "Não existe nenhum mecanismo que possa garantir isso, mas um mecanismo amplamente utilizado para este fim é o uso de validação cruzada.\n",
    "\n",
    "A idéia é simples: devemos testar o classificador variando o valor de $k$, e depois devemos escolher o $k$ que obteve o melhor resultado para usar no mundo real. No entanto, não é aconselhado testar os diferentes valores de $k$ com o conjunto de teste, uma vez que estaria \"tunando\" o modelo para o conjunto de teste! Desta forma, o resultado não seria confiável para extrapolar para avaliar o comportamento do sistema no mundo real. Assim, uma das idéias é dividir o conjunto de treino em dois conjuntos: treino e validação. Desta forma, o conjunto de treino é sempre usado para treinar o modelo, mas a avaliação dos hiperparâmetros ($k$, no caso do KNN) é feita no conjunto de validação! O desempenho do sistema é avaliado no conjunto de teste, usando os melhores hiperparametros encontrados no conjunto de validação.\n",
    "\n",
    "Veja o código-exemplo abaixo, que implementa a validação cruzada para otimização do hiperparametro $k$ do KNN. Os comentários apresentados no exemplo anterior foram removidos, e somente comentários relacionados ao novo procedimento são mostrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia p/ k = 1: 0.99\n",
      "acurácia p/ k = 3: 0.99\n",
      "acurácia p/ k = 5: 0.98\n",
      "acurácia p/ k = 7: 0.98\n",
      "acurácia p/ k = 9: 0.98\n",
      "melhor k: 3\n",
      "acurácia no teste p/ k = 3: 0.96\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_digits(return_X_y=True)\n",
    "\n",
    "#Vamos dividir o dataset com 80% no treino e 20% no teste.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)\n",
    "#E agora vamos dividir o conjunto de treino em 80% para treino, e 20% para validação.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, shuffle=False)\n",
    "\n",
    "#A lista de ks a serem testados\n",
    "ks = [1, 3, 5, 7, 9]\n",
    "accs = []\n",
    "\n",
    "#Testar o conjunto de validação para todos os ks candidatos!\n",
    "for k in ks:\n",
    "    misses = 0\n",
    "    hits = 0    \n",
    "\n",
    "    #Para cada exemplo no conjunto de validação\n",
    "    for i, x in enumerate(X_val):\n",
    "        #Classificar o exemplo. Se o exemplo estiver correto (for igual do gabarito)\n",
    "        if knn(X_train, Y_train, x, k) == Y_val[i]:\n",
    "            #incrementar os acertos\n",
    "            hits+=1\n",
    "        else:\n",
    "            #Senão, incrementar os erros\n",
    "            misses+=1\n",
    "    #salvar a acurácia do modelo com o valor atual de k\n",
    "    accs.append((hits / float(hits + misses)))\n",
    "    print (\"acurácia p/ k = %d: %.02f\" % (k, accs[-1]))\n",
    "\n",
    "#Escolher o k cuja acurácia foi máxima no conjunto de validação!\n",
    "k = ks[np.argmax(accs)]\n",
    "\n",
    "print (\"melhor k: %d\" % k)\n",
    "\n",
    "misses = 0\n",
    "hits = 0    \n",
    "\n",
    "#Para cada exemplo no conjunto de teste.\n",
    "for i, x in enumerate(X_test):\n",
    "    #Classificar o exemplo. Se o exemplo estiver correto (for igual do gabarito)\n",
    "    #Note que o k escolhido é aquele cuja acurácia foi máxima no conjunto de validação!\n",
    "    #Não usamos o conjunto de teste até agora!\n",
    "    if knn(X_train, Y_train, x, k) == Y_test[i]:\n",
    "        #incrementar os acertos\n",
    "        hits+=1\n",
    "    else:\n",
    "        #Senão, incrementar os erros\n",
    "        misses+=1\n",
    "\n",
    "#A acurácia é dada por acertos / (acertos + erros).\n",
    "print (\"acurácia no teste p/ k = %d: %.02f\" % (k, hits / float(hits + misses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
